# Configuration for training microsoft/phi-2 for the 'harmless' objective.
# This configuration uses the built-in, "internal" judge.

model:
  policy_model_name: "microsoft/phi-2"
  
  # === Judge Configuration for TinyLlama ===
  judge_type: "internal"
  judge_model_name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  
  # This key is ignored when judge_type is "internal"
  # ollama_model_name: "gemma:27b"
  
  quantization_bits: 4
  use_flash_attention: true
  gradient_checkpointing: true

lora:
  r: 32
  alpha: 64
  dropout: 0.1

training:
  objective: "harmless"
  total_steps: 1500
  batch_size: 2
  mini_batch_size: 1
  gradient_accumulation_steps: 2
  learning_rate: 1.4e-5
  save_interval: 500

data:
  max_prompt_tokens: 256
  max_response_tokens: 384